{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.26.4)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement gensimnltk (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for gensimnltk\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch pandas numpy gensimnltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a8fb4a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('cleaned_wine_training_data.csv')\n",
    "# the data is already cleaned, so we can just tokenize the words\n",
    "# tokenize the description data\n",
    "X['description'] = X['description'].apply(lambda x: word_tokenize(x))\n",
    "# print(X['price'].isnull().values.any())\n",
    "# print(\"BEFORE\",len(X))\n",
    "X.dropna(subset= ['description'], inplace=True)\n",
    "X.dropna(subset= ['price'], inplace=True)\n",
    "# print(X['price'].isnull().values.any())\n",
    "# print(\"AFTER:\", len(X))\n",
    "\n",
    "# train a word2vec model on the description data\n",
    "prelim = Word2Vec(X['description'], min_count=1, workers=3, window=3, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d3dc1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "# Writing a custom dataset: customize data for each batch \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets): \n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        # self.hidden_layer = None TO DO ADD TO THE PARAMS or not idk \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "28b5ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the NN architecture\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        #Define each layer separately\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # self.dropout = nn.Dropout(p = 0.2) #randomly zeros elements of the input tensor with probability p\n",
    "        # self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "        #Define each layer sequentially \n",
    "        # self.nn = nn.Sequential(nn.Linear(input_size,hidden_size), nn.Linear(hidden_size, output_size), nn.ReLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Separate layer pass\n",
    "        x = self.fc1(x)\n",
    "        # x = self.dropout(x)\n",
    "        # x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # self.hidden_layer = h\n",
    "        return x\n",
    "        # we cant return BOTH \n",
    "    \n",
    "        # Sequential forward pass\n",
    "        # return self.nn(x)\n",
    "    \n",
    " \n",
    "# Define hyperparameters DONE: WHAT ARE OUR INPUTS \n",
    "input_size = prelim.vector_size\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "\n",
    "# Set the seed for PyTorch's random number generator\n",
    "torch.manual_seed(24)\n",
    "np.random.seed(24)\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = NeuralNet(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a429a4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a7e6ad5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train() # specifies that the model is being trained (tunable parameters)\n",
    "# model.eval() # specifices that the model is not being trained (don't use dropout and batchnorm)\n",
    "\n",
    "# #with torch.no_grad(): # use this to not tune model parameters \n",
    "\n",
    "# # model.cuda() # If you are on a gpu, this will push the model onto the gpu\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b80631c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: loss = CUSTOM MSE - CONTRASTIVE LOSS # define a loss function\n",
    "loss = torch.nn.MSELoss()\n",
    "learning_rate = 0.001 # define a learning rate \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) # define an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1590b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded input data: torch.Size([93964, 75, 100])\n"
     ]
    }
   ],
   "source": [
    "input_data_embeddings = []\n",
    "max_length = 0\n",
    "\n",
    "for review in X['description']:\n",
    "    embedding_sequence = [prelim.wv[word] for word in review if word in prelim.wv]\n",
    "    input_data_embeddings.append(embedding_sequence)\n",
    "    max_length = max(max_length, len(embedding_sequence))\n",
    "\n",
    "# Pad sequences to the same length\n",
    "input_data_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in input_data_embeddings]\n",
    "input_data_tensors_padded = pad_sequence(input_data_tensors, batch_first=True)\n",
    "\n",
    "# You can check the shape of input_data_tensors_padded to see the maximum length\n",
    "print(\"Shape of padded input data:\", input_data_tensors_padded.shape)\n",
    "\n",
    "# Assuming X[\"price\"] contains your target prices\n",
    "target_tensors = torch.tensor(X[\"price\"], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6e027e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example data and actual values \n",
    "# # data = torch.randn(100, 10)  # 100 samples, 10 features\n",
    "# # targets = torch.randint(0, 2, (100,))  # 100 actual values (0 or 1)\n",
    "# #TO DO: GRAB COLS FROM CSVC \n",
    "\n",
    "# # Inputs need to be tensors\n",
    " \n",
    "# # Extract Word2Vec embeddings for input data\n",
    "# # Assuming 'input_data' contains your input sentences or documents\n",
    "\n",
    "# input_data_embeddings = []\n",
    "# for review in X['description']:\n",
    "#     print(review, len(review))\n",
    "#     # sentence_embedding = [print(prelim.wv[word]) for word in review if word in prelim.wv]\n",
    "#     # for word in review:\n",
    "#     #     print(prelim.wv[word])\n",
    "\n",
    "#     # input_data_embeddings.append(sentence_embedding)\n",
    "\n",
    "# print(\"len at the end\", len(input_data_embeddings))\n",
    "\n",
    "# # Convert input data embeddings to tensors\n",
    "# prices = X[\"price\"]\n",
    "# input_data_tensors = torch.tensor(input_data_embeddings, dtype=torch.float32)\n",
    "# target_tensors = torch.tensor(prices, dtype=torch.float32)\n",
    "\n",
    "# # TO DO : Forward pass through the neural network\n",
    "# # output = model(input_data_tensors)\n",
    "\n",
    "# print(input_data_tensors)\n",
    "# print(type(prices), prices)\n",
    "\n",
    "# # Create custom dataset instance\n",
    "# # dataset = CustomDataset(data, targets)\n",
    "dataset = CustomDataset(input_data_tensors_padded, target_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "10d46213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 248.8989\n",
      "Epoch [2/15], Loss: 202.1680\n",
      "Epoch [3/15], Loss: 1358.3790\n",
      "Epoch [4/15], Loss: 270.4036\n",
      "Epoch [5/15], Loss: 2013.9700\n",
      "Epoch [6/15], Loss: 318.1687\n",
      "Epoch [7/15], Loss: 620.0620\n",
      "Epoch [8/15], Loss: 248.8893\n",
      "Epoch [9/15], Loss: 237.8450\n",
      "Epoch [10/15], Loss: 583.8531\n",
      "Epoch [11/15], Loss: 449.6649\n",
      "Epoch [12/15], Loss: 235.6612\n",
      "Epoch [13/15], Loss: 5863.2974\n",
      "Epoch [14/15], Loss: 534.7920\n",
      "Epoch [15/15], Loss: 28.7218\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "batch_size = 20\n",
    "\n",
    "# Create DataLoader #TO DO: MODIFY TO TAKE IN 2 POINTS AT A TIME \n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True) # multiprocessing supported with num_workers = n\n",
    "model.train()\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_data, batch_targets in dataloader:\n",
    "        # print(type(batch_data), batch_data.shape)\n",
    "        # print(type(batch_targets), batch_targets.shape)\n",
    "\n",
    "        #batch_data = batch_data.cuda() # push data onto gpu\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_data)\n",
    "        # print(\"this was a number before\", outputs)\n",
    "        temp = outputs\n",
    "        # print(\"OUTPUTS should now be a tensor object instead of tuple\", type(outputs))\n",
    "        \n",
    "        # calculate loss between output from model and actual values \n",
    "        pred = loss(temp, batch_targets)\n",
    "        # print(\"PRED\", pred)\n",
    "        # print(\"outputs new :\", temp)\n",
    "        # print(\"TRUE Y\", batch_targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()# zero gradient buffers\n",
    "        pred.backward()# backprop\n",
    "        optimizer.step()# update \n",
    "    \n",
    "    # Print loss every epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {pred.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d0e10ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating on test set\n",
    "# model.eval()\n",
    "# test_data = torch.randn(20, 10)\n",
    "# test_targets = torch.randint(0, 2, (20,))\n",
    "# TO DO: validation data columns \n",
    "\n",
    "# with torch.no_grad():\n",
    "#     model_pred = model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "71bdfd70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# getting indices of predictions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(\u001b[43mmodel_pred\u001b[49m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Compare predictions with targets\u001b[39;00m\n\u001b[1;32m      5\u001b[0m correct \u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m test_targets)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# getting indices of predictions\n",
    "_, predicted = torch.max(model_pred, 1)\n",
    "    \n",
    "# Compare predictions with targets\n",
    "correct = (predicted == test_targets).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / test_targets.size(0)\n",
    "\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also use a dataloader \n",
    "test_dataset = CustomDataset(test_data, test_targets)\n",
    "dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last = False) \n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch_data, batch_targets in dataloader:\n",
    "        batch_data, batch_targets = batch_data.to(device), batch_targets.to(device)\n",
    "        pred = model(batch_data)\n",
    "        test_loss += loss(pred, batch_targets).item()\n",
    "        correct += (pred.argmax(1) == batch_targets).type(torch.float).sum().item()\n",
    "print(\"test loss: \", test_loss)\n",
    "print(\"number correct: \", correct)\n",
    "print(\"accuracy: \", correct / test_targets.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), \"448_test_nn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0921de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "nn = NeuralNet(input_size, hidden_size, output_size) # need model shape/parameters\n",
    "nn.load_state_dict(torch.load(\"448_test_nn.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27cf38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model \n",
    "torch.save(model, '448_test_nn_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model, don't need model shape or parameters\n",
    "nn = torch.load('448_test_nn_full.pth')\n",
    "print(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b61222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pipreqs\n",
      "  Downloading pipreqs-0.5.0-py3-none-any.whl (33 kB)\n",
      "Collecting nbconvert<8.0.0,>=7.11.0\n",
      "  Downloading nbconvert-7.16.1-py3-none-any.whl (257 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.3/257.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting docopt==0.6.2\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting yarg==0.1.9\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Collecting ipython==8.12.3\n",
      "  Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.3/798.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jedi>=0.16 in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (0.18.1)\n",
      "Requirement already satisfied: traitlets>=5 in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (5.7.1)\n",
      "Requirement already satisfied: decorator in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (5.1.1)\n",
      "Requirement already satisfied: backcall in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (2.11.2)\n",
      "Requirement already satisfied: stack-data in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (0.1.6)\n",
      "Requirement already satisfied: appnope in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (0.1.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./miniconda/lib/python3.10/site-packages (from ipython==8.12.3->pipreqs) (4.8.0)\n",
      "Requirement already satisfied: requests in ./miniconda/lib/python3.10/site-packages (from yarg==0.1.9->pipreqs) (2.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (3.1.2)\n",
      "Requirement already satisfied: tinycss2 in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (1.2.1)\n",
      "Collecting mistune<4,>=2.0.3\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (22.0)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (5.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (1.5.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (5.7.0)\n",
      "Requirement already satisfied: defusedxml in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.7.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.5.13)\n",
      "Requirement already satisfied: beautifulsoup4 in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (4.11.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (2.1.1)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./miniconda/lib/python3.10/site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs) (4.1.0)\n",
      "Requirement already satisfied: webencodings in ./miniconda/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in ./miniconda/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./miniconda/lib/python3.10/site-packages (from jedi>=0.16->ipython==8.12.3->pipreqs) (0.8.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./miniconda/lib/python3.10/site-packages (from jupyter-core>=4.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.5.2)\n",
      "Requirement already satisfied: nest-asyncio in ./miniconda/lib/python3.10/site-packages (from nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (1.5.6)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in ./miniconda/lib/python3.10/site-packages (from nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (7.4.8)\n",
      "Requirement already satisfied: fastjsonschema in ./miniconda/lib/python3.10/site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in ./miniconda/lib/python3.10/site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (4.16.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./miniconda/lib/python3.10/site-packages (from pexpect>4.3->ipython==8.12.3->pipreqs) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./miniconda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython==8.12.3->pipreqs) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./miniconda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.3.2.post1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda/lib/python3.10/site-packages (from requests->yarg==0.1.9->pipreqs) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./miniconda/lib/python3.10/site-packages (from requests->yarg==0.1.9->pipreqs) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda/lib/python3.10/site-packages (from requests->yarg==0.1.9->pipreqs) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda/lib/python3.10/site-packages (from requests->yarg==0.1.9->pipreqs) (1.26.13)\n",
      "Requirement already satisfied: asttokens in ./miniconda/lib/python3.10/site-packages (from stack-data->ipython==8.12.3->pipreqs) (2.0.5)\n",
      "Requirement already satisfied: executing in ./miniconda/lib/python3.10/site-packages (from stack-data->ipython==8.12.3->pipreqs) (0.8.3)\n",
      "Requirement already satisfied: pure-eval in ./miniconda/lib/python3.10/site-packages (from stack-data->ipython==8.12.3->pipreqs) (0.2.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./miniconda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./miniconda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.18.0)\n",
      "Requirement already satisfied: entrypoints in ./miniconda/lib/python3.10/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (0.4)\n",
      "Requirement already satisfied: tornado>=6.2 in ./miniconda/lib/python3.10/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (6.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in ./miniconda/lib/python3.10/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (23.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniconda/lib/python3.10/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert<8.0.0,>=7.11.0->pipreqs) (2.8.2)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=7b12a8ca2790fecb53f3e539e70407429262eb45ddf02acf887ef06c5bab9f41\n",
      "  Stored in directory: /Users/ahung/Library/Caches/pip/wheels/7c/d7/8d/2156234738063e3d4a39ba77dc677046100e62766b53807189\n",
      "Successfully built docopt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: docopt, mistune, yarg, ipython, nbconvert, pipreqs\n",
      "  Attempting uninstall: mistune\n",
      "    Found existing installation: mistune 0.8.4\n",
      "    Uninstalling mistune-0.8.4:\n",
      "      Successfully uninstalled mistune-0.8.4\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.7.0\n",
      "    Uninstalling ipython-8.7.0:\n",
      "      Successfully uninstalled ipython-8.7.0\n",
      "  Attempting uninstall: nbconvert\n",
      "    Found existing installation: nbconvert 6.5.4\n",
      "    Uninstalling nbconvert-6.5.4:\n",
      "      Successfully uninstalled nbconvert-6.5.4\n",
      "Successfully installed docopt-0.6.2 ipython-8.12.3 mistune-3.0.2 nbconvert-7.16.1 pipreqs-0.5.0 yarg-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ca012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
